{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size:  65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(\"vocab size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {char: i for i, char in enumerate(chars)}\n",
    "itos = {i: char for i, char in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s] # takes a string, returns list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # takes list of integers, returns a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 1, 39, 51, 1, 52, 39, 60, 42, 43, 43, 54]\n",
      "i am navdeep\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"i am navdeep\"))\n",
    "print(decode([47, 1, 39, 51, 1, 52, 39, 60, 42, 43, 43, 54]))\n",
    "assert decode(encode(\"i am navdeep\")) == \"i am navdeep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4 # independent sequences that will be processed in parallel\n",
    "block_size = 8 # maximum context length\n",
    "\n",
    "def get_batch(split):\n",
    "    \"\"\"\n",
    "    returns a batch (x, y) of batch_size = 4 arrays\n",
    "    arrays are of size block_size = 8\n",
    "    \"\"\"\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # get batch_size=4 random numbers from len(data) - block_size. minus block_size is to prevent overflow\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # stack batch_size=4 arrays cotaining block_size=8 elements from data starting from index in ix\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix]) # stack batch_size=4 arrays cotaining block_size=8 elements from data starting from index+1 in ix\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[52, 42,  8,  0,  0, 23, 21, 26],\n",
      "        [45, 53, 42, 57,  0, 23, 43, 43],\n",
      "        [52,  1, 61, 39, 57,  1, 51, 53],\n",
      "        [39, 49, 12,  1, 27,  1, 58, 56]])\n",
      "tensor([[42,  8,  0,  0, 23, 21, 26, 19],\n",
      "        [53, 42, 57,  0, 23, 43, 43, 54],\n",
      "        [ 1, 61, 39, 57,  1, 51, 53, 56],\n",
      "        [49, 12,  1, 27,  1, 58, 56, 39]])\n",
      "[52] --> 42\n",
      "[52, 42] --> 8\n",
      "[52, 42, 8] --> 0\n",
      "[52, 42, 8, 0] --> 0\n",
      "[52, 42, 8, 0, 0] --> 23\n",
      "[52, 42, 8, 0, 0, 23] --> 21\n",
      "[52, 42, 8, 0, 0, 23, 21] --> 26\n",
      "[52, 42, 8, 0, 0, 23, 21, 26] --> 19\n",
      "[45] --> 53\n",
      "[45, 53] --> 42\n",
      "[45, 53, 42] --> 57\n",
      "[45, 53, 42, 57] --> 0\n",
      "[45, 53, 42, 57, 0] --> 23\n",
      "[45, 53, 42, 57, 0, 23] --> 43\n",
      "[45, 53, 42, 57, 0, 23, 43] --> 43\n",
      "[45, 53, 42, 57, 0, 23, 43, 43] --> 54\n",
      "[52] --> 1\n",
      "[52, 1] --> 61\n",
      "[52, 1, 61] --> 39\n",
      "[52, 1, 61, 39] --> 57\n",
      "[52, 1, 61, 39, 57] --> 1\n",
      "[52, 1, 61, 39, 57, 1] --> 51\n",
      "[52, 1, 61, 39, 57, 1, 51] --> 53\n",
      "[52, 1, 61, 39, 57, 1, 51, 53] --> 56\n",
      "[39] --> 49\n",
      "[39, 49] --> 12\n",
      "[39, 49, 12] --> 1\n",
      "[39, 49, 12, 1] --> 27\n",
      "[39, 49, 12, 1, 27] --> 1\n",
      "[39, 49, 12, 1, 27, 1] --> 58\n",
      "[39, 49, 12, 1, 27, 1, 58] --> 56\n",
      "[39, 49, 12, 1, 27, 1, 58, 56] --> 39\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "print(xb)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b][:t+1]\n",
    "        target = yb[b][t]\n",
    "        print(f'{context.tolist()} --> {target}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
